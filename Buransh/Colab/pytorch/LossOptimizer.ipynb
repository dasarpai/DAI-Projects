{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LossOptimizer.ipynb","provenance":[{"file_id":"1hW5a5mg2MQa7Q2whMVinFFBRMKmdQB5e","timestamp":1615013231107}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"dG6otAHj0IWf"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WJvWZjzR0RMl"},"source":["# 1) Design model (input, output, forward pass with different layers)\r\n","# 2) Construct loss and optimizer\r\n","# 3) Training loop\r\n","#       - Forward = compute prediction and loss\r\n","#       - Backward = compute gradients\r\n","#       - Update weights\r\n","\r\n","import torch\r\n","import torch.nn as nn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TVMp2ANT0V-a"},"source":["# Linear regression\r\n","# f = w * x \r\n","\r\n","# here : f = 2 * x\r\n","\r\n","# 0) Training samples\r\n","X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\r\n","Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yMkDCTbc0W2l"},"source":["# 1) Design Model: Weights to optimize and forward function\r\n","w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PfR-rTyN0aWB"},"source":["def forward(x):\r\n","    return w * x\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"flPP_D2X0c2G","executionInfo":{"status":"ok","timestamp":1615005878310,"user_tz":-330,"elapsed":4378,"user":{"displayName":"usha rengaraju","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilW5hFfGX88ie8T8j8_ZSx4mUGdCwmVpf7vWSKfA=s64","userId":"04805119296002868129"}},"outputId":"e54c6bec-7720-40c8-dfce-fb2e9dde114f"},"source":["print(f'Prediction before training: f(5) = {forward(5).item():.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Prediction before training: f(5) = 0.000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g6yEe5n50fPr"},"source":["# 2) Define loss and optimizer\r\n","learning_rate = 0.01\r\n","n_iters = 100\r\n","\r\n","# callable function\r\n","loss = nn.MSELoss()\r\n","\r\n","optimizer = torch.optim.SGD([w], lr=learning_rate)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FKwXr4700Riq","executionInfo":{"status":"ok","timestamp":1615005878315,"user_tz":-330,"elapsed":4350,"user":{"displayName":"usha rengaraju","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilW5hFfGX88ie8T8j8_ZSx4mUGdCwmVpf7vWSKfA=s64","userId":"04805119296002868129"}},"outputId":"3efac39a-8bac-4b07-ad40-f3551dfd4448"},"source":["# 3) Training loop\r\n","for epoch in range(n_iters):\r\n","    # predict = forward pass\r\n","    y_predicted = forward(X)\r\n","\r\n","    # loss\r\n","    l = loss(Y, y_predicted)\r\n","\r\n","    # calculate gradients = backward pass\r\n","    l.backward()\r\n","\r\n","    # update weights\r\n","    optimizer.step()\r\n","\r\n","    # zero the gradients after updating\r\n","    optimizer.zero_grad()\r\n","\r\n","    if epoch % 10 == 0:\r\n","        print('epoch ', epoch+1, ': w = ', w, ' loss = ', l)\r\n","\r\n","print(f'Prediction after training: f(5) = {forward(5).item():.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["epoch  1 : w =  tensor(0.3000, requires_grad=True)  loss =  tensor(30., grad_fn=<MseLossBackward>)\n","epoch  11 : w =  tensor(1.6653, requires_grad=True)  loss =  tensor(1.1628, grad_fn=<MseLossBackward>)\n","epoch  21 : w =  tensor(1.9341, requires_grad=True)  loss =  tensor(0.0451, grad_fn=<MseLossBackward>)\n","epoch  31 : w =  tensor(1.9870, requires_grad=True)  loss =  tensor(0.0017, grad_fn=<MseLossBackward>)\n","epoch  41 : w =  tensor(1.9974, requires_grad=True)  loss =  tensor(6.7705e-05, grad_fn=<MseLossBackward>)\n","epoch  51 : w =  tensor(1.9995, requires_grad=True)  loss =  tensor(2.6244e-06, grad_fn=<MseLossBackward>)\n","epoch  61 : w =  tensor(1.9999, requires_grad=True)  loss =  tensor(1.0176e-07, grad_fn=<MseLossBackward>)\n","epoch  71 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(3.9742e-09, grad_fn=<MseLossBackward>)\n","epoch  81 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(1.4670e-10, grad_fn=<MseLossBackward>)\n","epoch  91 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(5.0768e-12, grad_fn=<MseLossBackward>)\n","Prediction after training: f(5) = 10.000\n"],"name":"stdout"}]}]}