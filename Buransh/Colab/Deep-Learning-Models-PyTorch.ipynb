{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPnjXq8PkSkeCSbm1Y8fsyV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["PyTorch Tutorial: How to Develop Deep Learning Models with Python   \n","https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/"],"metadata":{"id":"LcvG6Iq-Ghe_"}},{"cell_type":"code","source":["# pytorch mlp for binary classification\n","from numpy import vstack\n","from pandas import read_csv\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch.utils.data import random_split\n","from torch import Tensor\n","from torch.nn import Linear\n","from torch.nn import ReLU\n","from torch.nn import Sigmoid\n","from torch.nn import Module\n","from torch.optim import SGD\n","from torch.nn import BCELoss\n","from torch.nn.init import kaiming_uniform_\n","from torch.nn.init import xavier_uniform_"],"metadata":{"id":"CGRzJHKfGgOL","executionInfo":{"status":"ok","timestamp":1681364019670,"user_tz":-330,"elapsed":5,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# dataset definition\n","class CSVDataset(Dataset):\n","    # load the dataset\n","    def __init__(self, path):\n","        # load the csv file as a dataframe\n","        df = read_csv(path, header=None)\n","        # store the inputs and outputs\n","        self.X = df.values[:, :-1]\n","        self.y = df.values[:, -1]\n","        # ensure input data is floats\n","        self.X = self.X.astype('float32')\n","        # label encode target and ensure the values are floats\n","        self.y = LabelEncoder().fit_transform(self.y)\n","        self.y = self.y.astype('float32')\n","        self.y = self.y.reshape((len(self.y), 1))\n"," \n","    # number of rows in the dataset\n","    def __len__(self):\n","        return len(self.X)\n"," \n","    # get a row at an index\n","    def __getitem__(self, idx):\n","        return [self.X[idx], self.y[idx]]\n"," \n","    # get indexes for train and test rows\n","    def get_splits(self, n_test=0.33):\n","        # determine sizes\n","        test_size = round(n_test * len(self.X))\n","        train_size = len(self.X) - test_size\n","        # calculate the split\n","        return random_split(self, [train_size, test_size])"],"metadata":{"id":"rCPCAq6wGvGL","executionInfo":{"status":"ok","timestamp":1681364062314,"user_tz":-330,"elapsed":926,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# model definition\n","class MLP(Module):\n","    # define model elements\n","    def __init__(self, n_inputs):\n","        super(MLP, self).__init__()\n","\n","        # input to first hidden layer\n","        self.hidden1 = Linear(n_inputs, 10)\n","        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n","        self.act1 = ReLU()\n","\n","        # second hidden layer\n","        self.hidden2 = Linear(10, 8)\n","        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n","        self.act2 = ReLU()\n","        \n","        # third hidden layer and output\n","        self.hidden3 = Linear(8, 1)\n","        xavier_uniform_(self.hidden3.weight)\n","        self.act3 = Sigmoid()\n"," \n","    # forward propagate input\n","    def forward(self, X):\n","        # input to first hidden layer\n","        X = self.hidden1(X)\n","        X = self.act1(X)\n","         # second hidden layer\n","        X = self.hidden2(X)\n","        X = self.act2(X)\n","        # third hidden layer and output\n","        X = self.hidden3(X)\n","        X = self.act3(X)\n","        return X\n"," "],"metadata":{"id":"fUQfDxUzHCZE","executionInfo":{"status":"ok","timestamp":1681364106533,"user_tz":-330,"elapsed":548,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# prepare the dataset\n","def prepare_data(path):\n","    # load the dataset\n","    dataset = CSVDataset(path)\n","    # calculate split\n","    train, test = dataset.get_splits()\n","    # prepare data loaders\n","    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n","    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n","    return train_dl, test_dl"],"metadata":{"id":"30SESnbyHaGw","executionInfo":{"status":"ok","timestamp":1681364227105,"user_tz":-330,"elapsed":619,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# train the model\n","def train_model(train_dl, model):\n","    # define the optimization\n","    criterion = BCELoss()\n","    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n","    # enumerate epochs\n","    for epoch in range(100):\n","        # enumerate mini batches\n","        for i, (inputs, targets) in enumerate(train_dl):\n","            # clear the gradients\n","            optimizer.zero_grad()\n","            # compute the model output\n","            yhat = model(inputs)\n","            # calculate loss\n","            loss = criterion(yhat, targets)\n","            # credit assignment\n","            loss.backward()\n","            # update model weights\n","            optimizer.step()"],"metadata":{"id":"eSmKEbskHjer","executionInfo":{"status":"ok","timestamp":1681364240357,"user_tz":-330,"elapsed":8,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":[" # evaluate the model\n","def evaluate_model(test_dl, model):\n","    predictions, actuals = list(), list()\n","    for i, (inputs, targets) in enumerate(test_dl):\n","        # evaluate the model on the test set\n","        yhat = model(inputs)\n","        # retrieve numpy array\n","        yhat = yhat.detach().numpy()\n","        actual = targets.numpy()\n","        actual = actual.reshape((len(actual), 1))\n","        # round to class values\n","        yhat = yhat.round()\n","        # store\n","        predictions.append(yhat)\n","        actuals.append(actual)\n","    predictions, actuals = vstack(predictions), vstack(actuals)\n","    # calculate accuracy\n","    acc = accuracy_score(actuals, predictions)\n","    return acc"],"metadata":{"id":"O2LgqfZEHnAM","executionInfo":{"status":"ok","timestamp":1681364257835,"user_tz":-330,"elapsed":5,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# make a class prediction for one row of data\n","def predict(row, model):\n","    # convert row to data\n","    row = Tensor([row])\n","    # make prediction\n","    yhat = model(row)\n","    # retrieve numpy array\n","    yhat = yhat.detach().numpy()\n","    return yhat"],"metadata":{"id":"YzvJh5pwHrrj","executionInfo":{"status":"ok","timestamp":1681364274271,"user_tz":-330,"elapsed":11,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# prepare the data\n","path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n","train_dl, test_dl = prepare_data(path)\n","print(len(train_dl.dataset), len(test_dl.dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZeHws4UjH3e1","executionInfo":{"status":"ok","timestamp":1681364323574,"user_tz":-330,"elapsed":1081,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"383dbbe1-7d04-464c-f582-80ab83dd9109"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["235 116\n"]}]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rJa2cPByGMEW","executionInfo":{"status":"ok","timestamp":1681364360147,"user_tz":-330,"elapsed":1830,"user":{"displayName":"Hari Thapliyaal","userId":"09088303666341280217"}},"outputId":"5292cc4d-0649-4ad2-8afa-a0ce836373cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.922\n","Predicted: 0.998 (class=1)\n"]}],"source":["# define the network\n","model = MLP(34)\n","\n","# train the model\n","train_model(train_dl, model)\n","\n","# evaluate the model\n","acc = evaluate_model(test_dl, model)\n","print('Accuracy: %.3f' % acc)\n","\n","# make a single prediction (expect class=1)\n","row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n","yhat = predict(row, model)\n","print('Predicted: %.3f (class=%d)' % (yhat, yhat.round()))"]},{"cell_type":"code","source":[],"metadata":{"id":"zIxodHR7IzvG"},"execution_count":null,"outputs":[]}]}