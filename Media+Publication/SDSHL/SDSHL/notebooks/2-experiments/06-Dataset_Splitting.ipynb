{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths required\n",
    "datafolder_p = r'D:\\18-DS\\github\\SDSHL\\data\\processed'\n",
    "datafolder_e = r'D:\\18-DS\\github\\SDSHL\\data\\external'\n",
    "datafolder_i = r'D:\\18-DS\\github\\SDSHL\\data\\internal'\n",
    "modelfolder  = r'D:\\18-DS\\data\\models'\n",
    "\n",
    "vectorfolder_bert = modelfolder + r'\\BERT'\n",
    "vectorfolder_ft   = modelfolder + r'\\fasttext_wiki.hi'\n",
    "vectorfolder_standford = modelfolder + r'\\POS-Tagger-Hindi'\n",
    "\n",
    "train_datafile =datafolder_p+r'\\2-train.csv'\n",
    "test_datafile  =datafolder_p+r'\\2-test.csv'\n",
    "\n",
    "file_clean =datafolder_p+ r'\\2-Hinglish_Sarcasm_Clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.5\n"
     ]
    }
   ],
   "source": [
    "#split dataset for train & test\n",
    "\n",
    "df =pd.read_csv(file_clean, sep=\"\\t\", index_col='ID')\n",
    "y=df.label\n",
    "#df.index = df['ID']\n",
    "\n",
    "#Keep 10% for Testing\n",
    "train,test=train_test_split(df, stratify=y, test_size=0.1,random_state=1000)\n",
    "print (train.label.sum()/len(train), test.label.sum()/len(test))\n",
    "\n",
    "#create train & test file for non-fasttest modeling\n",
    "train = train[['label','sentence','sentence_wo_emo']]\n",
    "test  = test[['label','sentence','sentence_wo_emo']]\n",
    "train.to_csv(datafolder_p+ r'\\2-train.csv', sep=\"\\t\")\n",
    "test.to_csv (datafolder_p+ r'\\2-test.csv', sep=\"\\t\")\n",
    "\n",
    "\n",
    "#create train & test file for fasttest modeling\n",
    "train = train[['label','sentence']]\n",
    "test  = test[['label','sentence']]\n",
    "test['label']= test['label'].apply(lambda x: '__label__'+str(x))\n",
    "train['label']= train['label'].apply(lambda x: '__label__'+str(x))\n",
    "train.to_csv(datafolder_p+ r'\\3-train_ft.csv', sep=\"\\t\",  header=None, index=None)\n",
    "test.to_csv (datafolder_p+ r'\\3-test_ft.csv', sep=\"\\t\",  header=None, index=None)\n",
    "\n",
    "\n",
    "#create fasttext full file for creating fasttext word embedding for the complete file\n",
    "df  = df[['label','sentence']]\n",
    "df['label']= df['label'].apply(lambda x: '__label__'+str(x))\n",
    "df.to_csv(datafolder_p+ r'\\3-Hinglish_Sarcasm_Clean_ft.csv', sep=\"\\t\", header=None, index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expriment Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#', ' का सवाल पूछने वालों की ', ' पर ही सवाल है.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "xx = \"#AreYouSeriousRahul का सवाल पूछने वालों की SERIOUSNESS पर ही सवाल है.\"\n",
    "#xx = 'हम तो इस देश की अर्थ व्यवस्था का अर्थ समझना चाह रहे थे Manmohan . तुमने तो अर्थ व्यस्था की अर्थी ही निकाल दी .'\n",
    "r1 = re.split(r'[A-z]+',xx)\n",
    "\n",
    "print(r1)\n",
    "\n",
    "#list( df['sentence'].str.extract(r'[A-z]+') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FE = pd.read_csv(datafolder_p + r'\\4-features_pos.csv', sep='\\t', index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence_wo_emo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOUN, NOUN, ADP, VERB, AUX, AUX, PRON, PRON, N...</td>\n",
       "      <td>लोग वतन तक खा जाते हैं इसका इसे यकीन नहींमान ज...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PROPN, PART, VERB, AUX, PRON, NOUN, NOUN, DET,...</td>\n",
       "      <td>अंग्रेजी नहीं आती है इसलिए हिन्दी ट्विट ज्यादा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PROPN, ADP, VERB, AUX, AUX, NOUN, NOUN, PUNCT</td>\n",
       "      <td>कश्मीर में हो रहा है जल जिहाद .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NOUN, ADP, NOUN, ADJ, VERB, AUX, NOUN, ADP, NO...</td>\n",
       "      <td>संघर्ष में आदमी अकेला होता है सफलता में दुनिया...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NOUN, NOUN, VERB, AUX</td>\n",
       "      <td>मोहब्बत अंधी होती है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>PROPN, ADP, ADJ, NOUN, NOUN, DET, NOUN, ADP, P...</td>\n",
       "      <td>कांग्रेस से बड़ी महामारी बीमारी इस संसार मे को...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>PROPN, NOUN, VERB, PRON, PART, NOUN, ADP, PUNC...</td>\n",
       "      <td>टोटी चोरी करना किसी भी एंगल से ' आत्मनिर्भरता ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>NOUN, ADP, VERB, ADP, ADP, PART, PROPN, PUNCT,...</td>\n",
       "      <td>वायरस से बचने के लिए भी 'अल्कोहल'. ! और इकॉनमी...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9120</th>\n",
       "      <td>PRON, NOUN, PART, ADJ, NOUN, ADP, PROPN, ADP, ...</td>\n",
       "      <td>मेरे रुद्र भी पूरी तरहा से जी के निवेदन का पाल...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9121</th>\n",
       "      <td>DET, NOUN, ADP, NOUN, ADP, NUM, NOUN, ADP, VER...</td>\n",
       "      <td>जिस परिवार ने देश को 70 साल तक लुटा है , उससे ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2315 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    pos  \\\n",
       "ID                                                        \n",
       "1     NOUN, NOUN, ADP, VERB, AUX, AUX, PRON, PRON, N...   \n",
       "5     PROPN, PART, VERB, AUX, PRON, NOUN, NOUN, DET,...   \n",
       "6         PROPN, ADP, VERB, AUX, AUX, NOUN, NOUN, PUNCT   \n",
       "8     NOUN, ADP, NOUN, ADJ, VERB, AUX, NOUN, ADP, NO...   \n",
       "9                                 NOUN, NOUN, VERB, AUX   \n",
       "...                                                 ...   \n",
       "9117  PROPN, ADP, ADJ, NOUN, NOUN, DET, NOUN, ADP, P...   \n",
       "9118  PROPN, NOUN, VERB, PRON, PART, NOUN, ADP, PUNC...   \n",
       "9119  NOUN, ADP, VERB, ADP, ADP, PART, PROPN, PUNCT,...   \n",
       "9120  PRON, NOUN, PART, ADJ, NOUN, ADP, PROPN, ADP, ...   \n",
       "9121  DET, NOUN, ADP, NOUN, ADP, NUM, NOUN, ADP, VER...   \n",
       "\n",
       "                                        sentence_wo_emo  \n",
       "ID                                                       \n",
       "1     लोग वतन तक खा जाते हैं इसका इसे यकीन नहींमान ज...  \n",
       "5     अंग्रेजी नहीं आती है इसलिए हिन्दी ट्विट ज्यादा...  \n",
       "6                       कश्मीर में हो रहा है जल जिहाद .  \n",
       "8     संघर्ष में आदमी अकेला होता है सफलता में दुनिया...  \n",
       "9                                  मोहब्बत अंधी होती है  \n",
       "...                                                 ...  \n",
       "9117  कांग्रेस से बड़ी महामारी बीमारी इस संसार मे को...  \n",
       "9118  टोटी चोरी करना किसी भी एंगल से ' आत्मनिर्भरता ...  \n",
       "9119  वायरस से बचने के लिए भी 'अल्कोहल'. ! और इकॉनमी...  \n",
       "9120  मेरे रुद्र भी पूरी तरहा से जी के निवेदन का पाल...  \n",
       "9121  जिस परिवार ने देश को 70 साल तक लुटा है , उससे ...  \n",
       "\n",
       "[2315 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
