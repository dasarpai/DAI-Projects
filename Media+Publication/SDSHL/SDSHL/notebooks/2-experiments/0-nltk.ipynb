{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package indian to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package indian is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tag import tnt\n",
    "from nltk.corpus import indian\n",
    "nltk.download('indian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of TnT Tagging :  0.8914285714285715\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import tnt\n",
    "import nltk\n",
    "from nltk.corpus import indian\n",
    "train_data = indian.tagged_sents('hindi.pos')[0:530]\n",
    "test_data = indian.tagged_sents('hindi.pos')[530:]\n",
    "tnt_pos_tagger = tnt.TnT()\n",
    "tnt_pos_tagger.train(train_data)\n",
    "\n",
    "# evaluating \n",
    "a = tnt_pos_tagger.evaluate(test_data) \n",
    "  \n",
    "print (\"Accuracy of TnT Tagging : \", a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('केंद्र', 'NN'), ('की', 'PREP'), ('मोदी', 'NNP'), ('सरकार', 'NN'), ('ने', 'PREP'), ('शुक्रवार', 'NNP'), ('को', 'PREP'), ('अपना', 'PRP'), ('अंतरिम', 'Unk'), ('बजट', 'NN'), ('पेश', 'NVB'), ('किया', 'VFM'), ('.', 'SYM'), ('कार्यवाहक', 'Unk'), ('वित्त', 'Unk'), ('मंत्री', 'NN'), ('पीयूष', 'Unk'), ('गोयल', 'Unk'), ('ने', 'PREP'), ('अपने', 'PRP'), ('बजट', 'NN'), ('में', 'PREP'), ('किसान', 'Unk'), (',', 'PUNC'), ('मजदूर', 'Unk'), (',', 'PUNC'), ('करदाता', 'Unk'), (',', 'PUNC'), ('महिला', 'NNC'), ('वर्ग', 'Unk'), ('समेत', 'Unk'), ('हर', 'QF'), ('किसी', 'QW'), ('के', 'PREP'), ('लिए', 'PREP'), ('बंपर', 'Unk'), ('ऐलान', 'Unk'), ('किए', 'VFM'), ('.', 'SYM'), ('हालांकि', 'Unk'), (',', 'PUNC'), ('बजट', 'NN'), ('के', 'PREP'), ('बाद', 'PREP'), ('भी', 'RP'), ('टैक्स', 'Unk'), ('को', 'PREP'), ('लेकर', 'VRB'), ('काफी', 'INTF'), ('कन्फ्यूजन', 'Unk'), ('बना', 'VFM'), ('रहा', 'VAUX'), ('.', 'SYM'), ('केंद्र', 'NNC'), ('सरकार', 'NN'), ('के', 'PREP'), ('इस', 'PRP'), ('अंतरिम', 'Unk'), ('बजट', 'NN'), ('क्या', 'QW'), ('खास', 'JJ'), ('रहा', 'VAUX'), ('और', 'CC'), ('किसको', 'Unk'), ('क्या', 'QW'), ('मिला', 'VFM'), (',', 'PUNC'), ('आसान', 'Unk'), ('भाषा', 'Unk'), ('में', 'PREP'), ('यहां', 'NLOC'), ('समझें', 'Unk')]\n"
     ]
    }
   ],
   "source": [
    "doc = \"\"\"केंद्र की मोदी सरकार ने शुक्रवार को अपना अंतरिम बजट पेश किया. कार्यवाहक वित्त मंत्री पीयूष गोयल \\\n",
    "ने अपने बजट में किसान, मजदूर, करदाता, महिला वर्ग समेत हर किसी के लिए बंपर ऐलान किए. हालांकि, \\\n",
    "बजट के बाद भी टैक्स को लेकर काफी कन्फ्यूजन बना रहा. \\\n",
    "केंद्र सरकार के इस अंतरिम बजट क्या खास रहा और किसको क्या मिला, आसान भाषा में यहां समझें\"\"\"\n",
    "\n",
    "\n",
    "tagged_words = (tnt_pos_tagger.tag(nltk.word_tokenize(doc)))\n",
    "print(tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = indian.tagged_sents('hindi.pos')\n",
    "tnt_pos_tagger = tnt.TnT()\n",
    "tnt_pos_tagger.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('जब', 'RB'), ('तन्हा', 'Unk'), ('रातो', 'Unk'), ('में', 'PREP'), ('मोगैम्बो', 'Unk'), ('चिलाता', 'Unk'), ('है', 'VAUX'), ('की', 'PREP'), ('मोगैम्बो', 'Unk'), ('खुश', 'Unk'), ('हुवा', 'Unk'), ('तो', 'RP'), ('समझिये', 'Unk'), ('की', 'PREP'), ('मनमोहन', 'Unk'), ('सरकार', 'NN'), ('के', 'PREP'), ('बुरे', 'Unk'), ('सपने', 'Unk'), ('याद', 'Unk'), ('आ', 'VFM'), ('गये', 'VAUX'), (',', 'PUNC')]\n"
     ]
    }
   ],
   "source": [
    "text='जब तन्हा रातो में मोगैम्बो चिलाता है की मोगैम्बो खुश हुवा तो समझिये की मनमोहन सरकार के बुरे सपने याद आ गये,'\n",
    "tagged_words = (tnt_pos_tagger.tag(nltk.word_tokenize(text)))\n",
    "print(tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hindi.pos gives very bad result for pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('panlex_swadesh')\n",
    "nltk.corpus.CorpusReader.fileids #.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below is general command. But if we have corpus of tha langauge then only it will be useful.\n",
    "#nltk.corpus.<corpus>.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for english langugage 107 pos and other tag corpus available at http://www.nltk.org/nltk_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['And', 'now', 'for', 'something', 'completely', 'different']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.word_tokenize(\"And now for something completely different\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "f = codecs.open(datafolder_p+\"\\Hinglish_Sarcasm_FE.txt\",mode=\"r\",encoding=\"utf-8\")\n",
    "f2 = codecs.open(datafolder_p+\"\\Hinglish_Sarcasm_FE2.txt\",mode=\"w\",encoding=\"utf-8\")\n",
    "cnt = 0\n",
    "red = 0\n",
    "for i in f.readlines():\n",
    "\tcnt += 1\n",
    "\tif ('|UNK' in i) or ('B-NP' in i) or ('I-NP' in i) or ('|O' in i):\n",
    "\t\tred += 1\n",
    "\telse:\n",
    "\t\tf2.write(i)\n",
    "# print red\n",
    "# print cnt\n",
    "# print cnt-red\n",
    "\n",
    "f.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import indian\n",
    "from nltk.tag import tnt\n",
    "import string\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download()\n",
    "\n",
    "\n",
    "tagged_set = 'hindi.pos'\n",
    "word_set = indian.sents(tagged_set)\n",
    "count = 0\n",
    "for sen in word_set:\n",
    "    count = count + 1\n",
    "    sen = \"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in sen]).strip()\n",
    "    print (count, sen)\n",
    "print ('Total sentences in the tagged file are',count)\n",
    "\n",
    "train_perc = .9\n",
    "\n",
    "train_rows = int(train_perc*count)\n",
    "test_rows = train_rows + 1\n",
    "\n",
    "print ('Sentences to be trained',train_rows, 'Sentences to be tested against',test_rows)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "data = indian.tagged_sents(tagged_set)\n",
    "train_data = data[:train_rows]\n",
    "test_data = data[test_rows:]\n",
    "\n",
    "\n",
    "pos_tagger = tnt.TnT()\n",
    "pos_tagger.train(train_data)\n",
    "pos_tagger.evaluate(test_data)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "sentence_to_be_tagged = \"३९ गेंदों में दो चौकों और एक छक्के की मदद से ३४ रन बनाने वाले परोरे अंत तक आउट नहीं हुए ।\"\n",
    "\n",
    "tokenized = nltk.word_tokenize(sentence_to_be_tagged)\n",
    "\n",
    "\n",
    "print(pos_tagger.tag(tokenized))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "data.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\treebank.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of TnT Tagging :  0.875545003237643\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import tnt \n",
    "from nltk.corpus import treebank \n",
    "  \n",
    "# initializing training and testing set     \n",
    "train_data = treebank.tagged_sents()[:3000] \n",
    "test_data = treebank.tagged_sents()[3000:] \n",
    "  \n",
    "# initializing tagger \n",
    "tnt_tagging = tnt.TnT() \n",
    "  \n",
    "# training \n",
    "tnt_tagging.train(train_data) \n",
    "  \n",
    "# evaluating \n",
    "a = tnt_tagging.evaluate(test_data) \n",
    "  \n",
    "print (\"Accuracy of TnT Tagging : \", a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Memory', 'Unk'), ('networks', 'NNS'), ('with', 'IN'), ('an', 'DT'), ('architecture', 'NN'), ('similar', 'JJ'), ('to', 'TO'), ('(', 'Unk'), ('Mahata', 'Unk'), ('et', 'Unk'), ('al.', 'Unk'), (',', ','), ('2018', 'Unk'), (')', 'Unk'), (',', ','), ('are', 'VBP'), ('the', 'DT'), ('deep', 'Unk'), ('learning', 'NN'), ('models', 'NNS'), ('that', 'WDT'), ('were', 'VBD'), ('trained', 'VBN'), ('.', '.'), ('A', 'DT'), ('random', 'Unk'), ('classifier', 'Unk'), ('that', 'IN'), ('randomly', 'Unk'), ('generated', 'VBN'), ('predictions', 'Unk'), ('from', 'IN'), ('a', 'DT'), ('label', 'NN'), ('distribution', 'NN'), ('similar', 'JJ'), ('to', 'TO'), ('that', 'DT'), ('of', 'IN'), ('the', 'DT'), ('training', 'NN'), ('dataset', 'Unk'), ('was', 'VBD'), ('also', 'RB'), ('implemented', 'VBN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "doc ='''Memory networks with an architecture similar to (Mahata et al., 2018), are the deep\n",
    "learning models that were trained. A random classifier that randomly generated predictions from a label distribution similar to that\n",
    "of the training dataset was also implemented.'''\n",
    "\n",
    "tagged_words = (tnt_tagging.tag(nltk.word_tokenize(doc)))\n",
    "print(tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
