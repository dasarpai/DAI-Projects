{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspiration \n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2019/03/learn-to-use-elmo-to-extract-features-from-text/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d:\\18-ds has python get-pip.py file. run this.\n",
    "#python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7920, 3), (1953, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "train = pd.read_csv(\"train_2kmZucJ.csv\")\n",
    "test = pd.read_csv(\"test_oJQbWVk.csv\")\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.744192\n",
       "1    0.255808\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememories #unplug #relax #iphone #smartphone #wifi #connect... http://fb.me/6N3LsUpCu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that way ;) #iphone #cute #daventry #home http://instagr.am/p/Li_5_ujS4k/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to me about a question I have unless I pay them $19.95 for their stupid support!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0   1      0   \n",
       "1   2      0   \n",
       "2   3      0   \n",
       "3   4      0   \n",
       "4   5      1   \n",
       "\n",
       "                                                                                                                                 tweet  \n",
       "0     #fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone  \n",
       "1  Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/  \n",
       "2          We love this! Would you go? #talk #makememories #unplug #relax #iphone #smartphone #wifi #connect... http://fb.me/6N3LsUpCu  \n",
       "3                     I'm wired I know I'm George I was made that way ;) #iphone #cute #daventry #home http://instagr.am/p/Li_5_ujS4k/  \n",
       "4         What amazing service! Apple won't even talk to me about a question I have unless I pay them $19.95 for their stupid support!  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove URL's from train and test\n",
    "train['clean_tweet'] = train['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "\n",
    "test['clean_tweet'] = test['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation marks\n",
    "punctuation = '!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "train['clean_tweet'] = train['clean_tweet'].apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\n",
    "test['clean_tweet'] = test['clean_tweet'].apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\n",
    "\n",
    "# convert text to lowercase\n",
    "train['clean_tweet'] = train['clean_tweet'].str.lower()\n",
    "test['clean_tweet'] = test['clean_tweet'].str.lower()\n",
    "\n",
    "# remove numbers\n",
    "train['clean_tweet'] = train['clean_tweet'].str.replace(\"[0-9]\", \" \")\n",
    "test['clean_tweet'] = test['clean_tweet'].str.replace(\"[0-9]\", \" \")\n",
    "\n",
    "# remove whitespaces\n",
    "train['clean_tweet'] = train['clean_tweet'].apply(lambda x:' '.join(x.split()))\n",
    "test['clean_tweet'] = test['clean_tweet'].apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spaCy's language model\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# function to lemmatize text\n",
    "def lemmatization(texts):\n",
    "    output = []\n",
    "    for i in texts:\n",
    "        s = [token.lemma_ for token in nlp(i)]\n",
    "        output.append(' '.join(s))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"d:\\users\\admin\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"d:\\users\\admin\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"D:\\Users\\admin\\Anaconda3\\Scripts\\pip.exe\\__main__.py\", line 4, in <module>\n",
      "ModuleNotFoundError: No module named 'pip'\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean_tweet'] = lemmatization(train['clean_tweet'])\n",
    "test['clean_tweet'] = lemmatization(test['clean_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>5227</td>\n",
       "      <td>0</td>\n",
       "      <td>#Shana #tova!!! #Jewish #newyear everyone, may your new year be #sweet as an #apple with #honey #RoshHashanah</td>\n",
       "      <td>shana tova jewish newyear everyone , may -PRON- new year be sweet as an apple with honey roshhashanah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7076</th>\n",
       "      <td>7077</td>\n",
       "      <td>0</td>\n",
       "      <td>Taylor Swift joins opening acts Camila Cabello and Charli XCX for the start of her Reputation Tour</td>\n",
       "      <td>taylor swift join open act camila cabello and charli xcx for the start of -PRON- reputation tour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>1524</td>\n",
       "      <td>1</td>\n",
       "      <td>ah no way! can't watch the live streams because this stupid thing don't have flash player #needflashplayer :(</td>\n",
       "      <td>ah no way can not watch the live stream because this stupid thing do not have flash player needflashplayer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>1479</td>\n",
       "      <td>0</td>\n",
       "      <td>The Newlyweds!!!! #bride and #groom #wedding #photoshoot #iphone #popular #jj #ig @clauocho &amp; @tanklankenau http://instagr.am/p/UDIi1/</td>\n",
       "      <td>the newlywed bride and groom wedding photoshoot iphone popular jj ig clauocho tanklankenau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>1639</td>\n",
       "      <td>0</td>\n",
       "      <td>My gift to my mama dear! #imsomabaitNaDaughter #priceless #kind #december #samsung #wifii #hig...pic.twitter.com/oM2X2fUv</td>\n",
       "      <td>-PRON- gift to -PRON- mama dear imsomabaitnadaughter priceless kind december samsung wifii hig ... pic.twitter.comom x fuv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7431</th>\n",
       "      <td>7432</td>\n",
       "      <td>0</td>\n",
       "      <td>Just got to Face-Time my Mom! #jetsons having more familia w' #iPhone</td>\n",
       "      <td>just get to facetime -PRON- mom jetson have more familia w ' iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4444</th>\n",
       "      <td>4445</td>\n",
       "      <td>0</td>\n",
       "      <td>Imagine how heavy my heart is when I had to tell the wife she can't have an iphone! #smallmercies</td>\n",
       "      <td>imagine how heavy -PRON- heart be when i have to tell the wife -PRON- can not have an iphone smallmercie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7613</th>\n",
       "      <td>7614</td>\n",
       "      <td>0</td>\n",
       "      <td>One more, I swear. #vscocam #vsco #vscophile #littleprincedanny #alaskanmalamute #malamute #malamuteaddicts #notahusky #totallypawsomepups #dogsofinstagram #vscodog #portraitmode #iphonex #eastbay...</td>\n",
       "      <td>one more , i swear . vscocam vsco vscophile littleprincedanny alaskanmalamute malamute malamuteaddict notahusky totallypawsomepups dogsofinstagram vscodog portraitmode iphonex eastbay bayarea smil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6678</th>\n",
       "      <td>6679</td>\n",
       "      <td>0</td>\n",
       "      <td>My phone is too cute right now c: #iphone #kawaii http://instagram.com/p/hbyOejGCYE/</td>\n",
       "      <td>-PRON- phone be too cute right now c iphone kawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>1344</td>\n",
       "      <td>0</td>\n",
       "      <td>#yummy! Oh, my! #greek #yogurt #joy! #random #foodie #grocery #shopping #score! #caramel #apple #pie #nomnom http://fb.me/7xrnlsAU9</td>\n",
       "      <td>yummy oh , -PRON- greek yogurt joy random foodie grocery shopping score caramel apple pie nomnom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label  \\\n",
       "5226  5227      0   \n",
       "7076  7077      0   \n",
       "1523  1524      1   \n",
       "1478  1479      0   \n",
       "1638  1639      0   \n",
       "7431  7432      0   \n",
       "4444  4445      0   \n",
       "7613  7614      0   \n",
       "6678  6679      0   \n",
       "1343  1344      0   \n",
       "\n",
       "                                                                                                                                                                                                        tweet  \\\n",
       "5226                                                                                            #Shana #tova!!! #Jewish #newyear everyone, may your new year be #sweet as an #apple with #honey #RoshHashanah   \n",
       "7076                                                                                                       Taylor Swift joins opening acts Camila Cabello and Charli XCX for the start of her Reputation Tour   \n",
       "1523                                                                                            ah no way! can't watch the live streams because this stupid thing don't have flash player #needflashplayer :(   \n",
       "1478                                                                   The Newlyweds!!!! #bride and #groom #wedding #photoshoot #iphone #popular #jj #ig @clauocho & @tanklankenau http://instagr.am/p/UDIi1/   \n",
       "1638                                                                                My gift to my mama dear! #imsomabaitNaDaughter #priceless #kind #december #samsung #wifii #hig...pic.twitter.com/oM2X2fUv   \n",
       "7431                                                                                                                                    Just got to Face-Time my Mom! #jetsons having more familia w' #iPhone   \n",
       "4444                                                                                                        Imagine how heavy my heart is when I had to tell the wife she can't have an iphone! #smallmercies   \n",
       "7613  One more, I swear. #vscocam #vsco #vscophile #littleprincedanny #alaskanmalamute #malamute #malamuteaddicts #notahusky #totallypawsomepups #dogsofinstagram #vscodog #portraitmode #iphonex #eastbay...   \n",
       "6678                                                                                                                     My phone is too cute right now c: #iphone #kawaii http://instagram.com/p/hbyOejGCYE/   \n",
       "1343                                                                      #yummy! Oh, my! #greek #yogurt #joy! #random #foodie #grocery #shopping #score! #caramel #apple #pie #nomnom http://fb.me/7xrnlsAU9   \n",
       "\n",
       "                                                                                                                                                                                                  clean_tweet  \n",
       "5226                                                                                                    shana tova jewish newyear everyone , may -PRON- new year be sweet as an apple with honey roshhashanah  \n",
       "7076                                                                                                         taylor swift join open act camila cabello and charli xcx for the start of -PRON- reputation tour  \n",
       "1523                                                                                               ah no way can not watch the live stream because this stupid thing do not have flash player needflashplayer  \n",
       "1478                                                                                                               the newlywed bride and groom wedding photoshoot iphone popular jj ig clauocho tanklankenau  \n",
       "1638                                                                               -PRON- gift to -PRON- mama dear imsomabaitnadaughter priceless kind december samsung wifii hig ... pic.twitter.comom x fuv  \n",
       "7431                                                                                                                                      just get to facetime -PRON- mom jetson have more familia w ' iphone  \n",
       "4444                                                                                                 imagine how heavy -PRON- heart be when i have to tell the wife -PRON- can not have an iphone smallmercie  \n",
       "7613  one more , i swear . vscocam vsco vscophile littleprincedanny alaskanmalamute malamute malamuteaddict notahusky totallypawsomepups dogsofinstagram vscodog portraitmode iphonex eastbay bayarea smil...  \n",
       "6678                                                                                                                                                       -PRON- phone be too cute right now c iphone kawaii  \n",
       "1343                                                                                                         yummy oh , -PRON- greek yogurt joy random foodie grocery shopping score caramel apple pie nomnom  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ pip install \"tensorflow>=1.7.0\"\n",
    "$ pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Exporting/importing meta graphs is not supported when eager execution is enabled. No graph exists when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-4c0da589ac55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0melmo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://tfhub.dev/google/elmo/2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\module.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, spec, trainable, name, tags)\u001b[0m\n\u001b[0;32m    174\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m           tags=self._tags)\n\u001b[0m\u001b[0;32m    177\u001b[0m       \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py\u001b[0m in \u001b[0;36m_create_impl\u001b[1;34m(self, name, trainable, tags)\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkpoint_variables_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_export\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables_saver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, spec, meta_graph, trainable, checkpoint_path, name)\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[1;31m# TPU training code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mscope_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_init_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py\u001b[0m in \u001b[0;36m_init_state\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_init_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mvariable_tensor_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_state_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m     self._variable_map = recover_partitioned_variable_map(\n\u001b[0;32m    450\u001b[0m         get_node_map_from_tensor_map(variable_tensor_map))\n",
      "\u001b[1;32mD:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py\u001b[0m in \u001b[0;36m_create_state_graph\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[0mmeta_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[0minput_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m         import_scope=relative_scope_name)\n\u001b[0m\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m     \u001b[1;31m# Build a list from the variable name in the module definition to the actual\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\u001b[0m in \u001b[0;36mimport_meta_graph\u001b[1;34m(meta_graph_or_file, clear_devices, import_scope, **kwargs)\u001b[0m\n\u001b[0;32m   1451\u001b[0m   return _import_meta_graph_with_return_elements(meta_graph_or_file,\n\u001b[0;32m   1452\u001b[0m                                                  \u001b[0mclear_devices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1453\u001b[1;33m                                                  **kwargs)[0]\n\u001b[0m\u001b[0;32m   1454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\u001b[0m in \u001b[0;36m_import_meta_graph_with_return_elements\u001b[1;34m(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs)\u001b[0m\n\u001b[0;32m   1461\u001b[0m   \u001b[1;34m\"\"\"Import MetaGraph, and return both a saver and returned elements.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1462\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1463\u001b[1;33m     raise RuntimeError(\"Exporting/importing meta graphs is not supported when \"\n\u001b[0m\u001b[0;32m   1464\u001b[0m                        \u001b[1;34m\"eager execution is enabled. No graph exists when eager \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1465\u001b[0m                        \"execution is enabled.\")\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Exporting/importing meta graphs is not supported when eager execution is enabled. No graph exists when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a random sentence\n",
    "x = [\"Roasted ants are a popular snack in Columbia\"]\n",
    "\n",
    "# Extract ELMo features \n",
    "embeddings = elmo(x, signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elmo_vectors(x):\n",
    "    embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        # return average of ELMo features\n",
    "        return sess.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train = [train[i:i+100] for i in range(0,train.shape[0],100)]\n",
    "list_test = [test[i:i+100] for i in range(0,test.shape[0],100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ELMo embeddings\n",
    "elmo_train = [elmo_vectors(x['clean_tweet']) for x in list_train]\n",
    "elmo_test = [elmo_vectors(x['clean_tweet']) for x in list_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_train_new = np.concatenate(elmo_train, axis = 0)\n",
    "elmo_test_new = np.concatenate(elmo_test, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save elmo_train_new\n",
    "pickle_out = open(\"elmo_train_03032019.pickle\",\"wb\")\n",
    "pickle.dump(elmo_train_new, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "# save elmo_test_new\n",
    "pickle_out = open(\"elmo_test_03032019.pickle\",\"wb\")\n",
    "pickle.dump(elmo_test_new, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load elmo_train_new\n",
    "pickle_in = open(\"elmo_train_03032019.pickle\", \"rb\")\n",
    "elmo_train_new = pickle.load(pickle_in)\n",
    "\n",
    "# load elmo_train_new\n",
    "pickle_in = open(\"elmo_test_03032019.pickle\", \"rb\")\n",
    "elmo_test_new = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(elmo_train_new, \n",
    "                                                  train['label'],  \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "lreg = LogisticRegression()\n",
    "lreg.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = lreg.predict(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(yvalid, preds_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test set\n",
    "preds_test = lreg.predict(elmo_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare submission dataframe\n",
    "sub = pd.DataFrame({'id':test['id'], 'label':preds_test})\n",
    "\n",
    "# write predictions to a CSV file\n",
    "sub.to_csv(\"sub_lreg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are a few more NLP tasks where we can utilize ELMo:\n",
    "\n",
    "Machine Translation\n",
    "Language Modeling\n",
    "Text Summarization\n",
    "Named Entity Recognition\n",
    "Question-Answering Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
